{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stimulated emission protocol with BD followed by repeated Ï€ (n+1 and n+1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T22:24:50.689123Z",
     "start_time": "2021-07-31T22:24:48.399123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning could not load Chase AWG dll, check that dll located at 'C:\\_Lib\\python\\slab\\instruments\\awg\\chase\\dax22000_lib_DLL32.dll'\n",
      "Could not load InstrumentManagerWindow\n",
      "Warning could not load LDA labbrick dll, check that dll located at 'C:\\_Lib\\python\\slab\\instruments\\labbrick\\VNX_atten.dll'\n",
      "Warning could not load LMS labbrick dll, check that dll located at 'C:\\_Lib\\python\\slab\\instruments\\labbrick\\vnx_fmsynth.dll'\n",
      "Warning could not load LPS labbrick dll, check that dll located at 'C:\\_Lib\\python\\slab\\instruments\\labbrick\\VNX_dps.dll'\n",
      "Could not load labbrick\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\IPython\\qt.py:12: ShimWarning: The `IPython.qt` package has been deprecated since IPython 4.0. You should import from qtconsole instead.\n",
      "  warn(\"The `IPython.qt` package has been deprecated since IPython 4.0. \"\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\visa.py:13: FutureWarning: The visa module provided by PyVISA is being deprecated. You can replace `import visa` by `import pyvisa as visa` to achieve the same effect.\n",
      "\n",
      "The reason for the deprecation is the possible conflict with the visa package provided by the https://github.com/visa-sdk/visa-python which can result in hard to debug situations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pylab import*\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from h5py import File\n",
    "import pandas as pd\n",
    "from slab.dsfit import*\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import scipy as sc\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import argrelextrema\n",
    "# from qutip import *\n",
    "from h5py import File\n",
    "import os\n",
    "from slab.dataanalysis import get_next_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T22:25:30.002802Z",
     "start_time": "2021-07-31T22:25:29.916835Z"
    }
   },
   "outputs": [],
   "source": [
    "def coherent_state(n, alpha):\n",
    "    return np.exp(-abs(alpha)**2)*abs(alpha)**(2*n)/scipy.special.factorial(n)\n",
    "\n",
    "def line(x, m, b):\n",
    "    return m*x+b\n",
    "\n",
    "def proportional(x, m):\n",
    "    return m * x\n",
    "\n",
    "def gfromchi(chi,alpha,delta):\n",
    "    return np.sqrt(chi*delta*(delta+alpha)/alpha)\n",
    "\n",
    "def gaussfuncsum(p, x):\n",
    "    \"\"\"p[0]+p[1]/(1+(x-p[2])**2/p[3]**2)\"\"\"\n",
    "    y = 0\n",
    "    for ii in range(N):\n",
    "        y = y + p[3*ii+1]*exp(-(x-(p[3*ii+2]))**2/2/p[3*ii+3]**2)\n",
    "    return y\n",
    "\n",
    "def gaussfuncsum_with_baseline(x, *args):\n",
    "    \"\"\"p[0]+p[1]/(1+(x-p[2])**2/p[3]**2)\"\"\"\n",
    "    y = 0 \n",
    "    p = args\n",
    "#     print(len(p))\n",
    "    for ii in range(7):\n",
    "        y = y + p[3*ii+1]*exp(-(x-(p[3*ii+2]))**2/2/p[3*ii+3]**2)\n",
    "    y += p[0]\n",
    "    return y\n",
    "def fitgausssum(xdata, ydata, fitparams=None, domain=None, showfit=False,\n",
    "                showstartfit=False, label=\"\", debug=False):\n",
    "    \"\"\"fit lorentzian:\n",
    "        returns [offset,amplitude,center,hwhm]\"\"\"\n",
    "    if domain is not None:\n",
    "        fitdatax,fitdatay = selectdomain(xdata, ydata, domain)\n",
    "    else:\n",
    "        fitdatax = xdata\n",
    "        fitdatay = ydata\n",
    "    \n",
    "    if fitparams is None:\n",
    "        fitparams = 0*ones(3*N+1)\n",
    "        fitparams[0] = (fitdatay[0] + fitdatay[-1])/2.\n",
    "        fitparams[1] = max(fitdatay) - min(fitdatay)\n",
    "        fitparams[2] = fitdatax[np.argmax(fitdatay)]\n",
    "        fitparams[3] = (max(fitdatax) - min(fitdatax))/10.\n",
    "    \n",
    "    if debug==True: \n",
    "        print(fitparams)\n",
    "        \n",
    "    p1 = fitgeneral(fitdatax, fitdatay, gaussfuncsum, fitparams, domain=None, showfit=showfit, \n",
    "                    showstartfit=showstartfit, label=label)\n",
    "    p1[3]=abs(p1[3])\n",
    "    \n",
    "    return p1\n",
    "\n",
    "def fitgausssum_with_baseline(xdata, ydata, fitparams=None):\n",
    "    \"\"\"fit lorentzian:\n",
    "        returns [offset,amplitude,center,hwhm]\"\"\"\n",
    "    fitdatax = xdata\n",
    "    fitdatay = ydata\n",
    "#     if fitparams is None:\n",
    "#         fitparams = 0*ones(3*N+1)\n",
    "#         fitparams[0] = (fitdatay[0]+fitdatay[-1])/2.\n",
    "#         fitparams[1] = max(fitdatay)-min(fitdatay)\n",
    "#         fitparams[2] = fitdatax[np.argmax(fitdatay)]\n",
    "#         fitparams[3] = (max(fitdatax)-min(fitdatax))/10.\n",
    "    \n",
    "#     p1 = fitgeneral(fitdatax, fitdatay, gaussfuncsum_with_baseline, fitparams, domain=None, showfit=showfit,\n",
    "#                     showstartfit=showstartfit, label=label)\n",
    "#     bounds=(0, [3., 1., 0.5])\n",
    "        \n",
    "    popt, pcov = curve_fit(gaussfuncsum_with_baseline, fitdatax, fitdatay, p0=fitparams, bounds=(0, np.inf))\n",
    "\n",
    "    return popt, pcov\n",
    "\n",
    "def fitamp(p1):\n",
    "    fitamparray = []\n",
    "    fitfreqarray = []\n",
    "    n_peaks = int((len(p1)-1)/3)\n",
    "    for i in range(n_peaks):\n",
    "        fitamparray.append(p1[3*i+1])\n",
    "        fitfreqarray.append(p1[3*i+2])\n",
    "    return fitamparray , fitfreqarray\n",
    "\n",
    "def fitcoherentstate(peak_val):\n",
    "    xdata = np.arange(len(peak_val))\n",
    "    ydata = peak_val\n",
    "    popt, pcov = curve_fit(coherent_state, xdata, ydata)\n",
    "    return popt[0], np.sqrt(pcov[0][0])\n",
    "\n",
    "def expfunc2(x, p):\n",
    "    \"\"\"p[0]+p[1]*exp(-(x-p[2])/p[3])\"\"\"\n",
    "    return p[0]*np.exp**(-(x-p[1])/p[2])\n",
    "\n",
    "def fitexp2(xdata,ydata,fitparams=None,domain=None,showfit=False,showstartfit=False,label=\"\"):\n",
    "    \"\"\"Fit exponential decay (p[0]*exp(-(x-p[1])/p[2]))\"\"\"\n",
    "    if domain is not None:\n",
    "        fitdatax,fitdatay = selectdomain(xdata,ydata,domain)\n",
    "    else:\n",
    "        fitdatax=xdata\n",
    "        fitdatay=ydata\n",
    "    if fitparams is None:    \n",
    "        fitparams=[0.,0.,0.,0.]\n",
    "        fitparams[0]=fitdatay[0]-fitdatay[-1]\n",
    "        fitparams[1]=fitdatax[0]\n",
    "        fitparams[2]=(fitdatax[-1]-fitdatax[0])/5.\n",
    "    #print fitparams\n",
    "    p1 = fitgeneral(fitdatax, fitdatay, expfunc2, fitparams, domain=None, showfit=showfit, showstartfit=showstartfit,\n",
    "                    label=label)\n",
    "    return p1   \n",
    "\n",
    "def expfunc_test(x, a, b, c):\n",
    "    return b*np.exp(-(x-a)/c)\n",
    "\n",
    "def expfunc_baseline(x, a, b, c):\n",
    "    return a*np.exp(-x/b) + c\n",
    "\n",
    "def doublegauss(bins, *p):\n",
    "    a1, sigma1, mu1 = p[0], p[1], p[2]\n",
    "    a2, sigma2, mu2 = p[3], p[4], p[5]\n",
    "\n",
    "    y1 = a1*((1 / (np.sqrt(2 * np.pi) * sigma1)) *\n",
    "     np.exp(-0.5 * (1 / sigma1 * (bins - mu1))**2))\n",
    "    y2 = a2*((1 / (np.sqrt(2 * np.pi) * sigma2)) *\n",
    "     np.exp(-0.5 * (1 / sigma2 * (bins - mu2))**2))\n",
    "    y = y1+y2\n",
    "    \n",
    "    return y\n",
    "def gaussian2d(x, y, x0, y0, xalpha, yalpha, A):\n",
    "    return A * np.exp( -((x-x0)/xalpha)**2 -((y-y0)/yalpha)**2)\n",
    "\n",
    "\n",
    "def hist(filename=None, data=None, plot=True, ran=1.0):\n",
    "    \n",
    "    if data == None:\n",
    "        with File(filename,'r') as a:\n",
    "            ig = array(a['ig'])\n",
    "            qg = array(a['qg'])\n",
    "            ie = array(a['ie'])\n",
    "            qe = array(a['qe'])\n",
    "            a.close()\n",
    "    else:\n",
    "        ig = data[0]\n",
    "        qg = data[1]\n",
    "        ie = data[2]\n",
    "        qe = data[3]\n",
    "\n",
    "    numbins = 200\n",
    "    \n",
    "    xg, yg = np.median(ig), np.median(qg)\n",
    "    xe, ye = np.median(ie), np.median(qe)\n",
    "\n",
    "    if plot==True:\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(16, 4))\n",
    "        fig.tight_layout()\n",
    "\n",
    "        axs[0].scatter(ig, qg, label='g', color='b', marker='*')\n",
    "        axs[0].scatter(ie, qe, label='e', color='r', marker='*')\n",
    "        axs[0].scatter(xg, yg, color='k', marker='o')\n",
    "        axs[0].scatter(xe, ye, color='k', marker='o')\n",
    "        axs[0].set_xlabel('I (a.u.)')\n",
    "        axs[0].set_ylabel('Q (a.u.)')\n",
    "        axs[0].legend(loc='upper right')\n",
    "        axs[0].set_title('Unrotated')\n",
    "        axs[0].axis('equal')\n",
    "    \"\"\"Compute the rotation angle\"\"\"\n",
    "    theta = -arctan((ye-yg)/(xe-xg))\n",
    "    \"\"\"Rotate the IQ data\"\"\"\n",
    "    ig_new = ig*cos(theta) - qg*sin(theta)\n",
    "    qg_new = ig*sin(theta) + qg*cos(theta) \n",
    "    ie_new = ie*cos(theta) - qe*sin(theta)\n",
    "    qe_new = ie*sin(theta) + qe*cos(theta)\n",
    "    \n",
    "    \"\"\"New means of each blob\"\"\"\n",
    "    xg, yg = np.median(ig_new), np.median(qg_new)\n",
    "    xe, ye = np.median(ie_new), np.median(qe_new)\n",
    "\n",
    "    xlims = [xg-ran, xg+ran]\n",
    "    ylims = [yg-ran, yg+ran]\n",
    "\n",
    "    if plot==True:\n",
    "        axs[1].scatter(ig_new, qg_new, label='g', color='b', marker='*')\n",
    "        axs[1].scatter(ie_new, qe_new, label='e', color='r', marker='*')\n",
    "        axs[1].scatter(xg, yg, color='k', marker='o')\n",
    "        axs[1].scatter(xe, ye, color='k', marker='o')    \n",
    "        axs[1].set_xlabel('I (a.u.)')\n",
    "        axs[1].legend(loc='upper right')\n",
    "        axs[1].set_title('Rotated')\n",
    "        axs[1].axis('equal')\n",
    "\n",
    "        \"\"\"X and Y ranges for histogram\"\"\"\n",
    "        \n",
    "        ng, binsg, pg = axs[2].hist(ig_new, bins=numbins, range = xlims, color='b', label='g', alpha=0.5)\n",
    "    #     popt, pcov = curve_fit(doublegauss, xdata=binsg[:-1], ydata=ng, p0=p0)\n",
    "    #     mu_g = popt[2]\n",
    "    #     axs[2].plot(binsg, doublegauss(binsg, *popt), 'k--', linewidth=2 )\n",
    "        ne, binse, pe = axs[2].hist(ie_new, bins=numbins, range = xlims, color='r', label='e', alpha=0.5)\n",
    "    #     popt, pcov = curve_fit(doublegauss, xdata=binse[:-1], ydata=ne, p0=p0)\n",
    "    #     mu_e = popt[5]\n",
    "    #     axs[2].plot(binse, doublegauss(binse, *popt), 'k--', linewidth=2 )\n",
    "    #     axs[2].text(0.5*(mu_g + mu_e), 0.3*np.max(ne), \"$\\mu_{g}$ = %.4f \\n $\\mu_{e}$ = %.4f\"%(mu_g, mu_e), fontsize=16)\n",
    "\n",
    "        axs[2].set_xlabel('I(a.u.)')        \n",
    "        fig.show()\n",
    "        \n",
    "    else:        \n",
    "        ng, binsg = np.histogram(ig_new, bins=numbins, range = xlims)\n",
    "        ne, binse = np.histogram(ie_new, bins=numbins, range = xlims)\n",
    "\n",
    "    \"\"\"Compute the fidelity using overlap of the histograms\"\"\"\n",
    "    fid = np.abs(((np.cumsum(ng) - np.cumsum(ne)) / (0.5*ng.sum() + 0.5*ne.sum()))).max()\n",
    "\n",
    "    return fid, theta\n",
    "\n",
    "def rot_data(i, q, hist_filename=None):\n",
    "    \n",
    "    fid, theta = hist(hist_filename, ran=0.1)\n",
    "    print(fid, theta)\n",
    "    \"\"\"Rotate the IQ data\"\"\"\n",
    "    i_new = i*cos(theta) - q*sin(theta)\n",
    "    q_new = i*sin(theta) + q*cos(theta) \n",
    "    \n",
    "    return (i_new, q_new)\n",
    "\n",
    "\n",
    "def ramsfit(tR, n0, phi0, a):\n",
    "    T2 = 120e-6\n",
    "    dephase = 1/T2\n",
    "    detune = 2*np.pi*1e6 \n",
    "    chi = 2*np.pi*380e3\n",
    "    kappa = 2*np.pi*(8.0517e9)/8800\n",
    "    tau = []\n",
    "    z = []\n",
    "    res = []\n",
    "    for i,t in enumerate(tR):\n",
    "        tau.append((1-np.exp(-complex(kappa*tR[i], 2*chi*tR[i])))/complex(kappa, 2*chi))\n",
    "        z.append(np.exp(complex(-dephase*tR[i] , phi0 - detune*tR[i] - 2*n0*chi*tau[i])))\n",
    "        res.append(a*0.5*(1-np.imag(z[i])))\n",
    "    return np.array(res)\n",
    "\n",
    "def cav_response_new(p, x):\n",
    "    \"\"\"(p[0]/p[1])/(-1/2*p[0]/p[1] - 1j*(x-p[0])\"\"\"\n",
    "    ### p[0]=center freq, p[1]=kappa\n",
    "    temp = (p[1])/(p[1] - 1j*(x-p[0]))\n",
    "    return temp/max(abs(temp))\n",
    "\n",
    "def IF_window(p,x):\n",
    "    ### p[0] = center freq, p[1] = window width\n",
    "    temp = zeros(len(x)) + 1j*zeros(len(x))\n",
    "    for ii in range(len(x)):\n",
    "        if x[ii]>(p[0]-p[1]) and x[ii]<(p[0]+p[1]):\n",
    "            temp[ii] = 1/sqrt(2)*(1+1j)\n",
    "        else:\n",
    "            pass\n",
    "    return temp/max(abs(temp))\n",
    "\n",
    "def erf_t(A, sig, tc, tb, t):\n",
    "    #A-Amplitude, sig-Gaussian Filter Width, tc-Core Pulse length, tb - zero-amplitude buffer length\n",
    "    return (A/2)*(sc.special.erf((t-tb)/(sqrt(2)*sig))-sc.special.erf((t-tc-tb)/(sqrt(2)*sig)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T22:44:56.030585Z",
     "start_time": "2021-07-31T22:44:55.959494Z"
    }
   },
   "outputs": [],
   "source": [
    "class hmm_analysis:\n",
    "\n",
    "    def __init__(self, qubit_params = None, cavity_params = None, readout_params = None):\n",
    "        \n",
    "        self.qubit_params = qubit_params\n",
    "        self.cavity_params = cavity_params\n",
    "        self.readout_params = readout_params\n",
    "\n",
    "        \"\"\"All the timescales are in Î¼s\"\"\"\n",
    "        self.qubit_t1 = qubit_params['t1']\n",
    "        self.qubit_t2 = qubit_params['t2']\n",
    "        self.qubit_nth = qubit_params['nth']\n",
    "        \n",
    "        self.cavity_t1 = cavity_params['t1']\n",
    "        self.cavity_nth = cavity_params['nth']\n",
    "        \n",
    "        self.readout_len = readout_params['length']        \n",
    "        self.trigger_period = readout_params['trigger']\n",
    "        self.pi_length = readout_params['pi_pulse']\n",
    "\n",
    "    ##----------------------------------------------------------------##\n",
    "    def forward(self, meas_seq, T, E):\n",
    "        num_meas = len(meas_seq)\n",
    "        N = T.shape[0]\n",
    "        alpha = zeros((num_meas, N))\n",
    "        pi = [0.25, 0.25, 0.25, 0.25]\n",
    "        alpha[0] = pi*E[:,meas_seq[0]]\n",
    "        for t in range(1, num_meas):\n",
    "            alpha[t] = alpha[t-1].dot(T) * E[:, meas_seq[t]]\n",
    "        return alpha\n",
    "\n",
    "    def backward(self, meas_seq, T, E):\n",
    "        N = T.shape[0]\n",
    "        num_meas = len(meas_seq)\n",
    "        beta = zeros((N,num_meas))\n",
    "        beta[:,-1:] = 1\n",
    "        for t in reversed(range(num_meas-1)):\n",
    "            for n in range(N):\n",
    "                beta[n,t] = sum(beta[:,t+1] * T[n,:] * E[:, meas_seq[t+1]])\n",
    "        return beta\n",
    "\n",
    "    def likelihood(self, meas_seq, T, E):\n",
    "        # returns log P(Y  \\mid  model)\n",
    "        # using the forward part of the forward-backward algorithm\n",
    "        return  self.forward(meas_seq, T, E)[-1].sum()\n",
    "\n",
    "    def gamma(self, meas_seq, T, E):\n",
    "        alpha = self.forward(meas_seq, T, E)\n",
    "        beta  = self.backward(meas_seq, T, E)\n",
    "        obs_prob = self.likelihood(meas_seq, T, E)\n",
    "        return (multiply(alpha, beta.T) / obs_prob)\n",
    "\n",
    "    def viterbi(self, meas_seq, T, E):\n",
    "        # returns the most likely state sequence given observed sequence x\n",
    "        # using the Viterbi algorithm\n",
    "        num_meas = len(meas_seq)\n",
    "        N = T.shape[0]\n",
    "        delta = zeros((num_meas, N))\n",
    "        psi = zeros((num_meas, N))\n",
    "        pi = [0.25,0.25,0.25,0.25]\n",
    "        delta[0] = pi*E[:,meas_seq[0]]\n",
    "        for t in range(1, num_meas):\n",
    "            for j in range(N):\n",
    "                delta[t,j] = max(delta[t-1]*T[:,j]) * E[j, meas_seq[t]]\n",
    "                psi[t,j] = argmax(delta[t-1]*T[:,j])\n",
    "\n",
    "        # backtrack\n",
    "        states = zeros(num_meas, dtype=int32)\n",
    "        states[num_meas-1] = argmax(delta[num_meas-1])\n",
    "        for t in range(num_meas-2, -1, -1):\n",
    "            states[t] = psi[t+1, states[t+1]]\n",
    "        return states\n",
    "    ##----------------------------------------------------------------##\n",
    "    def alpha_awg_cal(self, cav_amp=0.4, cav_len=250):\n",
    "        # takes input array of amps and length and converts them to output array of alphas,\n",
    "        # using a calibration h5 file defined in the experiment config\n",
    "        # pull calibration data from file, handling properly in case of multimode cavity\n",
    "        cal_path = 'C:\\\\_Lib\\\\python\\\\slab\\\\experiments\\\\qm_opx\\\\drive_calibration'\n",
    "\n",
    "        fn_file = cal_path + '\\\\00000_2021_7_30_cavity_square.h5'\n",
    "\n",
    "        with File(fn_file, 'r') as f:\n",
    "            omegas = np.array(f['omegas'])\n",
    "            amps = np.array(f['amps'])\n",
    "\n",
    "        # assume zero frequency at zero amplitude, used for interpolation function\n",
    "        omegas = np.append(omegas, 0.0)\n",
    "        amps = np.append(amps, 0.0)\n",
    "\n",
    "        o_s = omegas\n",
    "        a_s = amps\n",
    "\n",
    "        # interpolate data, transfer_fn is a function that for each amp returns the corresponding omega\n",
    "        transfer_fn = scipy.interpolate.interp1d(a_s, o_s)\n",
    "\n",
    "        omega_desired = transfer_fn(cav_amp)\n",
    "        alpha = omega_desired * cav_len\n",
    "\n",
    "        \"\"\"Returns alpha in the cavity\"\"\"\n",
    "        return alpha\n",
    "        \n",
    "    ##----------------------------------------------------------------##\n",
    "    def openfile(self, filename):\n",
    "        \n",
    "        return File(filename,'r')\n",
    "\n",
    "    def stateprep(self, data_filename, fock_state =0,  at_end=True):\n",
    "        \n",
    "        \"\"\"Readout fidelities from an independent measurement\"\"\"\n",
    "        g_infidelity, e_infidelity = 0.0246, 0.0408\n",
    "        \n",
    "        self.a = self.openfile(data_filename)\n",
    "\n",
    "        num = pd.DataFrame(self.a['num'])[:]\n",
    "        bit = pd.DataFrame(self.a['bit'])[:]\n",
    "            \n",
    "        cav_amp = np.array(self.a['amp'])\n",
    "        cav_len = np.array(self.a['time'])\n",
    "        npi_m = int(np.array(self.a['pi_m']))\n",
    "        npi_n = int(np.array(self.a['pi_n']))\n",
    "\n",
    "        self.a.close()\n",
    "        \n",
    "        df = bit\n",
    "                \n",
    "        alpha = self.alpha_awg_cal(cav_amp, cav_len)\n",
    "        print('# of Ï€ at m= {}, at n = {}'.format(npi_m, npi_n))\n",
    "        print('Coherent drive: amp = {}, length = {} ns'.format(cav_amp, cav_len))\n",
    "\n",
    "        nx, ny = np.shape(df)\n",
    "                \n",
    "        \"\"\"Renaming the columns of repeated pi pulses\"\"\"\n",
    "        l = []\n",
    "        for i in range(ny):\n",
    "            l.append('Ï€%i'%i)\n",
    "        df.columns = l\n",
    "\n",
    "        df['n'] = num\n",
    "\n",
    "        cols = df.columns.tolist()\n",
    "        cols = cols[-1:] + cols[:-1]\n",
    "        df = df[cols].sort_values(by=['n'])\n",
    "\n",
    "        \"\"\"Find out the unique Fock levels and their occurences\"\"\"\n",
    "\n",
    "        (unique, counts) = np.unique(df['n'], return_counts=True)\n",
    "\n",
    "        print(unique, counts)\n",
    "        \n",
    "        p_m_counts = []\n",
    "        p_n_counts = []\n",
    "        \n",
    "        index = 0\n",
    "        for ii in range(len(unique)):\n",
    "            pm_temp = []\n",
    "            pn_temp = []\n",
    "            \n",
    "            fstate_in = unique[ii]\n",
    "            \"\"\"T and E matrices for the state prep part\"\"\"\n",
    "            if fstate_in ==0:\n",
    "                cavity_t1 = self.cavity_t1/(fstate_in+1)\n",
    "                Pnm =  self.cavity_nth * (1-np.exp(-self.trigger_period/cavity_t1))\n",
    "            else: \n",
    "                cavity_t1 = self.cavity_t1/(fstate_in)\n",
    "                Pnm =  (1-np.exp(-self.trigger_period/cavity_t1)) + self.cavity_nth * (1-np.exp(-self.trigger_period/cavity_t1))\n",
    "                \n",
    "            Pmn = 0 + 0 #assuming that the population at (n+1) is negligible and (n-1) we will estimate\\\n",
    "            Pge = self.qubit_nth * (1-np.exp(-self.trigger_period/self.qubit_t1)) +\\\n",
    "                (1-np.exp(-self.pi_length/self.qubit_t2))\n",
    "            Peg = (1-np.exp(-self.trigger_period/self.qubit_t1)) + \\\n",
    "                (1-np.exp(-self.pi_length/self.qubit_t2))\n",
    "\n",
    "            T_m = asarray([[(1-Pmn)*(1-Pge), (1-Pmn)*Pge, Pmn*Pge, Pmn*(1-Pge)],\n",
    "                 [(1-Pmn)*Peg, (1-Pmn)*(1-Peg), Pmn*(1-Peg), Pmn*Peg],\n",
    "                 [Pnm*(1-Pge), Pnm*Pge, (1-Pnm)*Pge, (1-Pnm)*(1-Pge)],\n",
    "                 [Pnm*Peg, Pnm*(1-Peg), (1-Pnm)*(1-Peg), (1-Pnm)*Peg]])\n",
    "\n",
    "            E_m = 0.5*asarray([[1-g_infidelity, g_infidelity],\n",
    "                [e_infidelity, 1- e_infidelity],\n",
    "                [1-g_infidelity, g_infidelity],\n",
    "                [e_infidelity, 1- e_infidelity]])     \n",
    "\n",
    "            \"\"\"T and E matrices for the second half of the experiment\"\"\"\n",
    "            cavity_t1 = self.cavity_t1/(fstate_in+1)\n",
    "            Pnm =  (1-np.exp(-self.trigger_period/cavity_t1)) + self.cavity_nth * (1-np.exp(-self.trigger_period/cavity_t1))\n",
    "\n",
    "            Pmn = 0 + 0 #assuming that the population at (n+1) is negligible and (n-1) we will estimate\\\n",
    "            Pge = self.qubit_nth * (1-np.exp(-self.trigger_period/self.qubit_t1)) +\\\n",
    "                (1-np.exp(-self.pi_length/self.qubit_t2))\n",
    "            Peg = (1-np.exp(-self.trigger_period/self.qubit_t1)) + \\\n",
    "                (1-np.exp(-self.pi_length/self.qubit_t2))\n",
    "\n",
    "            T_n = asarray([[(1-Pmn)*(1-Pge), (1-Pmn)*Pge, Pmn*Pge, Pmn*(1-Pge)],\n",
    "                 [(1-Pmn)*Peg, (1-Pmn)*(1-Peg), Pmn*(1-Peg), Pmn*Peg],\n",
    "                 [Pnm*(1-Pge), Pnm*Pge, (1-Pnm)*Pge, (1-Pnm)*(1-Pge)],\n",
    "                 [Pnm*Peg, Pnm*(1-Peg), (1-Pnm)*(1-Peg), (1-Pnm)*Peg]])\n",
    "\n",
    "            E_n = 0.5*asarray([[1-g_infidelity, g_infidelity],\n",
    "                [e_infidelity, 1- e_infidelity],\n",
    "                [1-g_infidelity, g_infidelity],\n",
    "                [e_infidelity, 1- e_infidelity]])\n",
    "            \n",
    "            for jj in range(counts[ii]):\n",
    "                \"\"\"State preparation probabilities at the end or at the beginning of m Ï€ pulses\"\"\"\n",
    "                meas_seq = df.iloc[index + jj][1:1+npi_m]\n",
    "                gamma_matrix = self.gamma(meas_seq, T_m, E_m)\n",
    "                if at_end==True: #Probablitity of state surviving till the end\n",
    "                    P0_last = gamma_matrix[-1,0] + gamma_matrix[-1,1]\n",
    "                    P1_last = gamma_matrix[-1,2] + gamma_matrix[-1,3]\n",
    "                else:#Probability at the beginnning\n",
    "                    P0_last = gamma_matrix[0,0] + gamma_matrix[0,1]\n",
    "                    P1_last = gamma_matrix[0,2] + gamma_matrix[0,3]   \n",
    "                pm_temp.append(P1_last/P0_last)          \n",
    "                \n",
    "                \"\"\"After the coherent drive, probabilities at the begining of n Ï€ pulses\"\"\"    \n",
    "                meas_seq = df.iloc[index + jj][npi_m:]\n",
    "                gamma_matrix = self.gamma(meas_seq, T_n, E_n)\n",
    "                P0_first = gamma_matrix[0,0] + gamma_matrix[0,1]\n",
    "                P1_first = gamma_matrix[0,2] + gamma_matrix[0,3]   \n",
    "                pn_temp.append(P1_first/P0_first)\n",
    "\n",
    "            index = index + counts[ii]\n",
    "            p_m_counts.append(pm_temp)\n",
    "            p_n_counts.append(pn_temp)\n",
    "\n",
    "        return alpha, unique, counts, p_m_counts, p_n_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the fidelity based on HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T15:19:39.453953Z",
     "start_time": "2021-08-04T15:19:15.899322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\00000_n0_bd_fidelity.h5\n",
      "# of Ï€ at m= 10, at n = 5\n",
      "Coherent drive: amp = 0.0, length = 400 ns\n",
      "[0 1 2 3] [9635   98  175   92]\n",
      "(9635, 2)\n",
      "6605\n",
      "0\n",
      "0 0.0\n"
     ]
    }
   ],
   "source": [
    "qubit_params = {'t1':100, 't2':136, 'nth':1e-2}\n",
    "cavity_params = {'t1':650, 'nth':0.001}\n",
    "readout_params = {'length':3.2, 'trigger':7.2, 'pi_pulse':3}\n",
    "\n",
    "expt_name = 'n0_bd_fidelity'\n",
    "fock_state = 0\n",
    "filelist = [fock_state]\n",
    "data_path = '..//data//'\n",
    "\n",
    "for ii, i in enumerate(filelist):\n",
    "    filename = \"..\\\\data\\\\\" + str(i).zfill(5) + \"_\"+expt_name+\".h5\"\n",
    "\n",
    "    p_m_counts = []\n",
    "    p_n_counts = []\n",
    "    alphas = []\n",
    "\n",
    "    print(filename)\n",
    "    obj = hmm_analysis(qubit_params=qubit_params, cavity_params=cavity_params, readout_params=readout_params)\n",
    "    alpha, unique, counts, p_m, p_n = obj.stateprep(data_filename=filename, at_end=True)\n",
    "    p_m_counts.extend(p_m[fock_state])\n",
    "    p_n_counts.extend(p_n[fock_state])        \n",
    "    alphas.append(alpha)\n",
    "\n",
    "df = pd.DataFrame(p_m_counts)\n",
    "\n",
    "df.columns = ['p_m']\n",
    "df['p_n'] = p_n_counts\n",
    "\n",
    "print(np.shape(df))\n",
    "th1 = 1e5\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "count_n = df['p_n'][df['p_n']>th2].count()\n",
    "print(count_n)\n",
    "\n",
    "count_p = df['p_n'][(df['p_m']>th1) & (df['p_n']>th2)].count()\n",
    "\n",
    "print(count_p, count_p/count_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T22:35:34.285515Z",
     "start_time": "2021-07-31T22:35:34.275503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6855215360664245"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6605/9635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T15:19:54.152372Z",
     "start_time": "2021-08-04T15:19:54.132359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9255\n",
      "0.9605604566683965\n"
     ]
    }
   ],
   "source": [
    "th1 = 1e3\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "\n",
    "print(count_m/9635)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T14:35:18.346659Z",
     "start_time": "2021-08-01T14:34:53.072789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\00001_n0_bd_fidelity.h5\n",
      "# of Ï€ at m= 10, at n = 5\n",
      "Coherent drive: amp = 0.0, length = 400 ns\n",
      "[0 1 2 3] [9903   29   44   24]\n",
      "(9903, 2)\n",
      "0\n",
      "0\n",
      "0 nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-33971c46e95f>:40: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  print(count_p, count_p/count_m)\n"
     ]
    }
   ],
   "source": [
    "qubit_params = {'t1':100, 't2':136, 'nth':5e-2}\n",
    "cavity_params = {'t1':650, 'nth':0.001}\n",
    "readout_params = {'length':3.2, 'trigger':7.2, 'pi_pulse':3}\n",
    "\n",
    "expt_name = 'n0_bd_fidelity'\n",
    "fock_state = 0\n",
    "filelist = [1]\n",
    "data_path = '..//data//'\n",
    "\n",
    "for ii, i in enumerate(filelist):\n",
    "    filename = \"..\\\\data\\\\\" + str(i).zfill(5) + \"_\"+expt_name+\".h5\"\n",
    "\n",
    "    p_m_counts = []\n",
    "    p_n_counts = []\n",
    "    alphas = []\n",
    "\n",
    "    print(filename)\n",
    "    obj = hmm_analysis(qubit_params=qubit_params, cavity_params=cavity_params, readout_params=readout_params)\n",
    "    alpha, unique, counts, p_m, p_n = obj.stateprep(data_filename=filename, at_end=False)\n",
    "    p_m_counts.extend(p_m[fock_state])\n",
    "    p_n_counts.extend(p_n[fock_state])        \n",
    "    alphas.append(alpha)\n",
    "\n",
    "df = pd.DataFrame(p_m_counts)\n",
    "\n",
    "df.columns = ['p_m']\n",
    "df['p_n'] = p_n_counts\n",
    "\n",
    "print(np.shape(df))\n",
    "th1 = 1e5\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "count_n = df['p_n'][df['p_n']>th2].count()\n",
    "print(count_n)\n",
    "\n",
    "count_p = df['p_n'][(df['p_m']>th1) & (df['p_n']>th2)].count()\n",
    "\n",
    "print(count_p, count_p/count_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T14:35:18.366713Z",
     "start_time": "2021-08-01T14:35:18.346659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "th1 = 1e3\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "\n",
    "print(count_m/9903)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T17:09:35.899091Z",
     "start_time": "2021-08-03T17:09:12.711215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\00000_n1_bd_fidelity.h5\n",
      "# of Ï€ at m= 10, at n = 5\n",
      "Coherent drive: amp = 0.0, length = 400 ns\n",
      "[0 1 2 3] [ 748 7779  637  836]\n",
      "(7779, 2)\n",
      "4716\n",
      "0\n",
      "0 0.0\n"
     ]
    }
   ],
   "source": [
    "qubit_params = {'t1':100, 't2':136, 'nth':5e-2}\n",
    "cavity_params = {'t1':650, 'nth':0.001}\n",
    "readout_params = {'length':3.2, 'trigger':7.2, 'pi_pulse':3}\n",
    "\n",
    "expt_name = 'n1_bd_fidelity'\n",
    "fock_state = 1\n",
    "filelist = [0]\n",
    "data_path = '..//data//'\n",
    "\n",
    "for ii, i in enumerate(filelist):\n",
    "    filename = \"..\\\\data\\\\\" + str(i).zfill(5) + \"_\"+expt_name+\".h5\"\n",
    "\n",
    "    p_m_counts = []\n",
    "    p_n_counts = []\n",
    "    alphas = []\n",
    "\n",
    "    print(filename)\n",
    "    obj = hmm_analysis(qubit_params=qubit_params, cavity_params=cavity_params, readout_params=readout_params)\n",
    "    alpha, unique, counts, p_m, p_n = obj.stateprep(data_filename=filename, at_end=False)\n",
    "    p_m_counts.extend(p_m[fock_state])\n",
    "    p_n_counts.extend(p_n[fock_state])        \n",
    "    alphas.append(alpha)\n",
    "\n",
    "df = pd.DataFrame(p_m_counts)\n",
    "\n",
    "df.columns = ['p_m']\n",
    "df['p_n'] = p_n_counts\n",
    "\n",
    "print(np.shape(df))\n",
    "th1 = 1e5\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "count_n = df['p_n'][df['p_n']>th2].count()\n",
    "print(count_n)\n",
    "\n",
    "count_p = df['p_n'][(df['p_m']>th1) & (df['p_n']>th2)].count()\n",
    "\n",
    "print(count_p, count_p/count_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T17:09:39.858964Z",
     "start_time": "2021-08-03T17:09:39.848963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n",
      "0.01619745468569225\n"
     ]
    }
   ],
   "source": [
    "th1 = 1e6\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "\n",
    "print(count_m/7779)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T17:26:04.245478Z",
     "start_time": "2021-08-03T17:25:40.475500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\00001_n1_bd_fidelity.h5\n",
      "# of Ï€ at m= 10, at n = 5\n",
      "Coherent drive: amp = 0.0, length = 400 ns\n",
      "[0 1 2 3] [ 881 7652  703  764]\n",
      "(7652, 2)\n",
      "0\n",
      "0\n",
      "0 nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-615d9fc729bc>:40: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  print(count_p, count_p/count_m)\n"
     ]
    }
   ],
   "source": [
    "qubit_params = {'t1':100, 't2':136, 'nth':5e-2}\n",
    "cavity_params = {'t1':650, 'nth':0.001}\n",
    "readout_params = {'length':3.2, 'trigger':7.2, 'pi_pulse':3}\n",
    "\n",
    "expt_name = 'n1_bd_fidelity'\n",
    "fock_state = 1\n",
    "filelist = [1]\n",
    "data_path = '..//data//'\n",
    "\n",
    "for ii, i in enumerate(filelist):\n",
    "    filename = \"..\\\\data\\\\\" + str(i).zfill(5) + \"_\"+expt_name+\".h5\"\n",
    "\n",
    "    p_m_counts = []\n",
    "    p_n_counts = []\n",
    "    alphas = []\n",
    "\n",
    "    print(filename)\n",
    "    obj = hmm_analysis(qubit_params=qubit_params, cavity_params=cavity_params, readout_params=readout_params)\n",
    "    alpha, unique, counts, p_m, p_n = obj.stateprep(data_filename=filename, at_end=True)\n",
    "    p_m_counts.extend(p_m[fock_state])\n",
    "    p_n_counts.extend(p_n[fock_state])        \n",
    "    alphas.append(alpha)\n",
    "\n",
    "df = pd.DataFrame(p_m_counts)\n",
    "\n",
    "df.columns = ['p_m']\n",
    "df['p_n'] = p_n_counts\n",
    "\n",
    "print(np.shape(df))\n",
    "th1 = 1e5\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "count_n = df['p_n'][df['p_n']>th2].count()\n",
    "print(count_n)\n",
    "\n",
    "count_p = df['p_n'][(df['p_m']>th1) & (df['p_n']>th2)].count()\n",
    "\n",
    "print(count_p, count_p/count_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T17:10:40.610140Z",
     "start_time": "2021-08-03T17:10:40.581580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.00013068478829064296\n"
     ]
    }
   ],
   "source": [
    "th1 = 1e6\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "\n",
    "print(count_m/7652)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T17:26:39.141657Z",
     "start_time": "2021-08-03T17:26:39.131644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7652\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "th1 = 1e-6\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "\n",
    "print(count_m/7652)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T15:03:33.284095Z",
     "start_time": "2021-08-01T15:03:09.023123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\00002_n1_bd_fidelity.h5\n",
      "# of Ï€ at m= 10, at n = 5\n",
      "Coherent drive: amp = 0.0, length = 400 ns\n",
      "[0 1 2 3] [ 921 7659  695  725]\n",
      "(7659, 2)\n",
      "146\n",
      "0\n",
      "0 0.0\n"
     ]
    }
   ],
   "source": [
    "qubit_params = {'t1':100, 't2':136, 'nth':5e-2}\n",
    "cavity_params = {'t1':650, 'nth':0.001}\n",
    "readout_params = {'length':3.2, 'trigger':7.2, 'pi_pulse':3}\n",
    "\n",
    "expt_name = 'n1_bd_fidelity'\n",
    "fock_state = 1\n",
    "filelist = [2]\n",
    "data_path = '..//data//'\n",
    "\n",
    "for ii, i in enumerate(filelist):\n",
    "    filename = \"..\\\\data\\\\\" + str(i).zfill(5) + \"_\"+expt_name+\".h5\"\n",
    "\n",
    "    p_m_counts = []\n",
    "    p_n_counts = []\n",
    "    alphas = []\n",
    "\n",
    "    print(filename)\n",
    "    obj = hmm_analysis(qubit_params=qubit_params, cavity_params=cavity_params, readout_params=readout_params)\n",
    "    alpha, unique, counts, p_m, p_n = obj.stateprep(data_filename=filename, at_end=False)\n",
    "    p_m_counts.extend(p_m[fock_state])\n",
    "    p_n_counts.extend(p_n[fock_state])        \n",
    "    alphas.append(alpha)\n",
    "\n",
    "df = pd.DataFrame(p_m_counts)\n",
    "\n",
    "df.columns = ['p_m']\n",
    "df['p_n'] = p_n_counts\n",
    "\n",
    "print(np.shape(df))\n",
    "th1 = 1e5\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "count_n = df['p_n'][df['p_n']>th2].count()\n",
    "print(count_n)\n",
    "\n",
    "count_p = df['p_n'][(df['p_m']>th1) & (df['p_n']>th2)].count()\n",
    "\n",
    "print(count_p, count_p/count_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T15:03:40.035571Z",
     "start_time": "2021-08-01T15:03:40.019048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353\n",
      "0.04608956782869826\n"
     ]
    }
   ],
   "source": [
    "th1 = 1e3\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "\n",
    "print(count_m/7659)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T22:58:51.024428Z",
     "start_time": "2021-07-31T22:58:28.521913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\00000_n2_bd_fidelity.h5\n",
      "# of Ï€ at m= 10, at n = 5\n",
      "Coherent drive: amp = 0.0, length = 400 ns\n",
      "[0 1 2 3] [1932 1275 5539 1254]\n",
      "(5539, 2)\n",
      "2552\n",
      "0\n",
      "0 0.0\n"
     ]
    }
   ],
   "source": [
    "qubit_params = {'t1':100, 't2':136, 'nth':5e-2}\n",
    "cavity_params = {'t1':650, 'nth':0.001}\n",
    "readout_params = {'length':3.2, 'trigger':7.2, 'pi_pulse':3}\n",
    "\n",
    "expt_name = 'n2_bd_fidelity'\n",
    "fock_state = 2\n",
    "filelist = [0]\n",
    "data_path = '..//data//'\n",
    "\n",
    "for ii, i in enumerate(filelist):\n",
    "    filename = \"..\\\\data\\\\\" + str(i).zfill(5) + \"_\"+expt_name+\".h5\"\n",
    "\n",
    "    p_m_counts = []\n",
    "    p_n_counts = []\n",
    "    alphas = []\n",
    "\n",
    "    print(filename)\n",
    "    obj = hmm_analysis(qubit_params=qubit_params, cavity_params=cavity_params, readout_params=readout_params)\n",
    "    alpha, unique, counts, p_m, p_n = obj.stateprep(data_filename=filename, at_end=False)\n",
    "    p_m_counts.extend(p_m[fock_state])\n",
    "    p_n_counts.extend(p_n[fock_state])        \n",
    "    alphas.append(alpha)\n",
    "\n",
    "df = pd.DataFrame(p_m_counts)\n",
    "\n",
    "df.columns = ['p_m']\n",
    "df['p_n'] = p_n_counts\n",
    "\n",
    "print(np.shape(df))\n",
    "th1 = 1e5\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "count_n = df['p_n'][df['p_n']>th2].count()\n",
    "print(count_n)\n",
    "\n",
    "count_p = df['p_n'][(df['p_m']>th1) & (df['p_n']>th2)].count()\n",
    "\n",
    "print(count_p, count_p/count_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T22:59:06.097860Z",
     "start_time": "2021-07-31T22:59:06.087844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4065\n",
      "0.7338869832099657\n"
     ]
    }
   ],
   "source": [
    "th1 = 1e3\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "\n",
    "print(count_m/5539)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T15:00:20.489314Z",
     "start_time": "2021-08-01T14:59:55.971576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\00001_n2_bd_fidelity.h5\n",
      "# of Ï€ at m= 10, at n = 5\n",
      "Coherent drive: amp = 0.0, length = 400 ns\n",
      "[0 1 2 3] [2054 1234 5509 1203]\n",
      "(5509, 2)\n",
      "1\n",
      "0\n",
      "0 0.0\n"
     ]
    }
   ],
   "source": [
    "qubit_params = {'t1':100, 't2':136, 'nth':5e-2}\n",
    "cavity_params = {'t1':650, 'nth':0.001}\n",
    "readout_params = {'length':3.2, 'trigger':7.2, 'pi_pulse':3}\n",
    "\n",
    "expt_name = 'n2_bd_fidelity'\n",
    "fock_state = 2\n",
    "filelist = [1]\n",
    "data_path = '..//data//'\n",
    "\n",
    "for ii, i in enumerate(filelist):\n",
    "    filename = \"..\\\\data\\\\\" + str(i).zfill(5) + \"_\"+expt_name+\".h5\"\n",
    "\n",
    "    p_m_counts = []\n",
    "    p_n_counts = []\n",
    "    alphas = []\n",
    "\n",
    "    print(filename)\n",
    "    obj = hmm_analysis(qubit_params=qubit_params, cavity_params=cavity_params, readout_params=readout_params)\n",
    "    alpha, unique, counts, p_m, p_n = obj.stateprep(data_filename=filename, at_end=False)\n",
    "    p_m_counts.extend(p_m[fock_state])\n",
    "    p_n_counts.extend(p_n[fock_state])        \n",
    "    alphas.append(alpha)\n",
    "\n",
    "df = pd.DataFrame(p_m_counts)\n",
    "\n",
    "df.columns = ['p_m']\n",
    "df['p_n'] = p_n_counts\n",
    "\n",
    "print(np.shape(df))\n",
    "th1 = 1e5\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "count_n = df['p_n'][df['p_n']>th2].count()\n",
    "print(count_n)\n",
    "\n",
    "count_p = df['p_n'][(df['p_m']>th1) & (df['p_n']>th2)].count()\n",
    "\n",
    "print(count_p, count_p/count_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T15:01:28.284244Z",
     "start_time": "2021-08-01T15:01:28.264296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0.0005445634416409512\n"
     ]
    }
   ],
   "source": [
    "th1 = 1e3\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "\n",
    "print(count_m/5509)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:21:40.374262Z",
     "start_time": "2021-08-01T18:21:16.865576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\00002_n2_bd_fidelity.h5\n",
      "# of Ï€ at m= 10, at n = 5\n",
      "Coherent drive: amp = 0.0, length = 400 ns\n",
      "[0 1 2 3] [2101 1256 5404 1239]\n",
      "(5404, 2)\n",
      "235\n",
      "0\n",
      "0 0.0\n"
     ]
    }
   ],
   "source": [
    "qubit_params = {'t1':100, 't2':136, 'nth':5e-2}\n",
    "cavity_params = {'t1':650, 'nth':0.001}\n",
    "readout_params = {'length':3.2, 'trigger':7.2, 'pi_pulse':3}\n",
    "\n",
    "expt_name = 'n2_bd_fidelity'\n",
    "fock_state = 2\n",
    "filelist = [2]\n",
    "data_path = '..//data//'\n",
    "\n",
    "for ii, i in enumerate(filelist):\n",
    "    filename = \"..\\\\data\\\\\" + str(i).zfill(5) + \"_\"+expt_name+\".h5\"\n",
    "\n",
    "    p_m_counts = []\n",
    "    p_n_counts = []\n",
    "    alphas = []\n",
    "\n",
    "    print(filename)\n",
    "    obj = hmm_analysis(qubit_params=qubit_params, cavity_params=cavity_params, readout_params=readout_params)\n",
    "    alpha, unique, counts, p_m, p_n = obj.stateprep(data_filename=filename, at_end=False)\n",
    "    p_m_counts.extend(p_m[fock_state])\n",
    "    p_n_counts.extend(p_n[fock_state])        \n",
    "    alphas.append(alpha)\n",
    "\n",
    "df = pd.DataFrame(p_m_counts)\n",
    "\n",
    "df.columns = ['p_m']\n",
    "df['p_n'] = p_n_counts\n",
    "\n",
    "print(np.shape(df))\n",
    "th1 = 1e5\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "count_n = df['p_n'][df['p_n']>th2].count()\n",
    "print(count_n)\n",
    "\n",
    "count_p = df['p_n'][(df['p_m']>th1) & (df['p_n']>th2)].count()\n",
    "\n",
    "print(count_p, count_p/count_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:21:50.743024Z",
     "start_time": "2021-08-01T18:21:50.723034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489\n",
      "0.09048852701702442\n"
     ]
    }
   ],
   "source": [
    "th1 = 1e3\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "\n",
    "print(count_m/5404)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T23:02:15.346808Z",
     "start_time": "2021-07-31T23:01:52.249171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\00000_n3_bd_fidelity.h5\n",
      "# of Ï€ at m= 10, at n = 5\n",
      "Coherent drive: amp = 0.0, length = 400 ns\n",
      "[0 1 2 3] [3965 2331 1079 2625]\n",
      "(2625, 2)\n",
      "873\n",
      "0\n",
      "0 0.0\n"
     ]
    }
   ],
   "source": [
    "qubit_params = {'t1':100, 't2':136, 'nth':5e-2}\n",
    "cavity_params = {'t1':650, 'nth':0.001}\n",
    "readout_params = {'length':3.2, 'trigger':7.2, 'pi_pulse':3}\n",
    "\n",
    "expt_name = 'n3_bd_fidelity'\n",
    "fock_state = 3\n",
    "filelist = [0]\n",
    "data_path = '..//data//'\n",
    "\n",
    "for ii, i in enumerate(filelist):\n",
    "    filename = \"..\\\\data\\\\\" + str(i).zfill(5) + \"_\"+expt_name+\".h5\"\n",
    "\n",
    "    p_m_counts = []\n",
    "    p_n_counts = []\n",
    "    alphas = []\n",
    "\n",
    "    print(filename)\n",
    "    obj = hmm_analysis(qubit_params=qubit_params, cavity_params=cavity_params, readout_params=readout_params)\n",
    "    alpha, unique, counts, p_m, p_n = obj.stateprep(data_filename=filename, at_end=False)\n",
    "    p_m_counts.extend(p_m[fock_state])\n",
    "    p_n_counts.extend(p_n[fock_state])        \n",
    "    alphas.append(alpha)\n",
    "\n",
    "df = pd.DataFrame(p_m_counts)\n",
    "\n",
    "df.columns = ['p_m']\n",
    "df['p_n'] = p_n_counts\n",
    "\n",
    "print(np.shape(df))\n",
    "th1 = 1e5\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "count_n = df['p_n'][df['p_n']>th2].count()\n",
    "print(count_n)\n",
    "\n",
    "count_p = df['p_n'][(df['p_m']>th1) & (df['p_n']>th2)].count()\n",
    "\n",
    "print(count_p, count_p/count_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:21:40.374262Z",
     "start_time": "2021-08-01T18:21:16.865576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567\n",
      "0.5969523809523809\n"
     ]
    }
   ],
   "source": [
    "th1 = 1e3\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "\n",
    "print(count_m/2625)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:41:52.783968Z",
     "start_time": "2021-08-01T18:41:29.644193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\00002_n3_bd_fidelity.h5\n",
      "# of Ï€ at m= 10, at n = 5\n",
      "Coherent drive: amp = 0.0, length = 400 ns\n",
      "[0 1 2 3] [3951 2393 1061 2595]\n",
      "(2595, 2)\n",
      "0\n",
      "0\n",
      "0 nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-58-c139f637f232>:40: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  print(count_p, count_p/count_m)\n"
     ]
    }
   ],
   "source": [
    "qubit_params = {'t1':100, 't2':136, 'nth':5e-2}\n",
    "cavity_params = {'t1':650, 'nth':0.001}\n",
    "readout_params = {'length':3.2, 'trigger':7.2, 'pi_pulse':3}\n",
    "\n",
    "expt_name = 'n3_bd_fidelity'\n",
    "fock_state = 3\n",
    "filelist = [2]\n",
    "data_path = '..//data//'\n",
    "\n",
    "for ii, i in enumerate(filelist):\n",
    "    filename = \"..\\\\data\\\\\" + str(i).zfill(5) + \"_\"+expt_name+\".h5\"\n",
    "\n",
    "    p_m_counts = []\n",
    "    p_n_counts = []\n",
    "    alphas = []\n",
    "\n",
    "    print(filename)\n",
    "    obj = hmm_analysis(qubit_params=qubit_params, cavity_params=cavity_params, readout_params=readout_params)\n",
    "    alpha, unique, counts, p_m, p_n = obj.stateprep(data_filename=filename, at_end=False)\n",
    "    p_m_counts.extend(p_m[fock_state])\n",
    "    p_n_counts.extend(p_n[fock_state])        \n",
    "    alphas.append(alpha)\n",
    "\n",
    "df = pd.DataFrame(p_m_counts)\n",
    "\n",
    "df.columns = ['p_m']\n",
    "df['p_n'] = p_n_counts\n",
    "\n",
    "print(np.shape(df))\n",
    "th1 = 1e5\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "count_n = df['p_n'][df['p_n']>th2].count()\n",
    "print(count_n)\n",
    "\n",
    "count_p = df['p_n'][(df['p_m']>th1) & (df['p_n']>th2)].count()\n",
    "\n",
    "print(count_p, count_p/count_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T18:43:12.732894Z",
     "start_time": "2021-08-01T18:43:12.722890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.0003853564547206166\n"
     ]
    }
   ],
   "source": [
    "th1 = 1e2\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "\n",
    "print(count_m/2595)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qubit_params = {'t1':100, 't2':136, 'nth':5e-2}\n",
    "cavity_params = {'t1':650, 'nth':0.001}\n",
    "readout_params = {'length':3.2, 'trigger':7.2, 'pi_pulse':3}\n",
    "\n",
    "expt_name = 'n3_bd_fidelity'\n",
    "fock_state = 3\n",
    "filelist = [1]\n",
    "data_path = '..//data//'\n",
    "\n",
    "for ii, i in enumerate(filelist):\n",
    "    filename = \"..\\\\data\\\\\" + str(i).zfill(5) + \"_\"+expt_name+\".h5\"\n",
    "\n",
    "    p_m_counts = []\n",
    "    p_n_counts = []\n",
    "    alphas = []\n",
    "\n",
    "    print(filename)\n",
    "    obj = hmm_analysis(qubit_params=qubit_params, cavity_params=cavity_params, readout_params=readout_params)\n",
    "    alpha, unique, counts, p_m, p_n = obj.stateprep(data_filename=filename, at_end=False)\n",
    "    p_m_counts.extend(p_m[fock_state])\n",
    "    p_n_counts.extend(p_n[fock_state])        \n",
    "    alphas.append(alpha)\n",
    "\n",
    "df = pd.DataFrame(p_m_counts)\n",
    "\n",
    "df.columns = ['p_m']\n",
    "df['p_n'] = p_n_counts\n",
    "\n",
    "print(np.shape(df))\n",
    "th1 = 1e5\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "count_n = df['p_n'][df['p_n']>th2].count()\n",
    "print(count_n)\n",
    "\n",
    "count_p = df['p_n'][(df['p_m']>th1) & (df['p_n']>th2)].count()\n",
    "\n",
    "print(count_p, count_p/count_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th1 = 1e3\n",
    "th2 = 1e8\n",
    "\n",
    "count_m = df['p_m'][df['p_m']>th1].count()\n",
    "print(count_m)\n",
    "\n",
    "print(count_m/2625)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "493.833px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
